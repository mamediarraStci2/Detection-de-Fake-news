"""
Interface utilisateur pour la d√©tection de fake news
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import joblib
import os
import time
import re
# Liste de mots associ√©s aux fake news (fr√©quemment trouv√©s dans les titres sensationnalistes)
FAKE_NEWS_WORDS = [
    'shocking', 'secret', 'they don\'t want you to know', 'conspiracy', 'hoax', 'scam', 
    'fake', 'miracle', 'shocking truth', 'government lies', 'exposed',
    'scandal', 'breaking', 'bombshell', 'urgent', 'alarming', 'censored', 'banned',
    'choquant', 'secret', 'complot', 'canular', 'arnaque', 'faux', 'miracle', 
    'v√©rit√© choquante', 'mensonges', 'complot', 'expos√©',
    'scandale', 'urgent', 'alarmant', 'censur√©', 'interdit'
]

# Mots communs dans les vraies news
REAL_NEWS_WORDS = [
    'report', 'according to', 'study finds', 'research', 'announced', 'published',
    'confirmed', 'stated', 'evidence', 'data', 'source', 'official', 'expert',
    'analysis', 'investigation', 'rapport', 'selon', '√©tude', 'recherche', 'annonc√©',
    'publi√©', 'confirm√©', 'd√©clar√©', 'preuve', 'donn√©es', 'source', 'officiel',
    'expert', 'analyse', 'enqu√™te'
]

# Cr√©ation d'une classe KMeans personnalis√©e pour √©viter les erreurs li√©es aux attributs manquants
class SimplifiedKMeans:
    def __init__(self, n_clusters=2, random_state=42):
        self.n_clusters = n_clusters
        self.random_state = random_state
        self.cluster_centers_ = None
        np.random.seed(random_state)
        self.fake_cluster = 0  # Par d√©faut, cluster 0 = fake news
    
    def fit(self, X):
        # Initialisation al√©atoire des centres
        self.cluster_centers_ = np.random.rand(self.n_clusters, X.shape[1])
        return self
    
    def predict(self, X):
        # Calcul des distances aux centres
        distances = np.linalg.norm(X[:, np.newaxis, :] - self.cluster_centers_[np.newaxis, :, :], axis=2)
        # Attribution au cluster le plus proche
        return np.argmin(distances, axis=1)
# Impl√©mentation simplifi√©e du pr√©processeur pour √©viter la d√©pendance √† langdetect
class SimpleTextPreprocessor:
    """Classe simplifi√©e pour le pr√©traitement des textes avec fonctionnalit√©s am√©lior√©es"""
    
    def __init__(self):
        self.tokenizer = None
        self.model = None
        # Liste de mots communs en fran√ßais pour la d√©tection de langue
        self.french_words = ['le', 'la', 'les', 'un', 'une', 'des', 'et', 'est', 'sont', 'ce', 'cette', 
                      'ces', 'mon', 'ton', 'son', 'notre', 'votre', 'leur', 'qui', 'que', 'dont',
                      'o√π', 'quoi', 'pourquoi', 'comment', 'quand', 'quel', 'quelle', '√†', 'au', 'aux']
    
    def detect_language(self, text):
        """D√©tecte la langue du texte de mani√®re simpifi√©e"""
        if not isinstance(text, str) or text.strip() == "":
            return 'en'
            
        text_lower = text.lower()
        # Compte le nombre de mots fran√ßais dans le texte
        french_word_count = sum(1 for word in self.french_words if f" {word} " in f" {text_lower} ")
        
        # Si au moins 3 mots fran√ßais sont d√©tect√©s, consid√®re le texte comme fran√ßais
        return 'fr' if french_word_count >= 3 else 'en'
    
    def preprocess_text(self, text):
        """Pr√©traitement am√©lior√© du texte"""
        if not isinstance(text, str) or text.strip() == "":
            return ""
        
        # D√©tection de la langue
        language = self.detect_language(text)
        
        # Nettoyage plus complet
        text = text.lower()
        
        # Suppression des URLs
        text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) if 're' in globals() else text.lower()
        
        # Suppression de la ponctuation
        for char in '.,;:!?()[]{}<>"\'':
            text = text.replace(char, ' ')
        
        # Suppression des espaces multiples
        while '  ' in text:
            text = text.replace('  ', ' ')
        
        # Analyse des mots-cl√©s (augmente la performance de d√©tection)
        fake_words_count = sum(1 for word in FAKE_NEWS_WORDS if word.lower() in text.lower())
        real_words_count = sum(1 for word in REAL_NEWS_WORDS if word.lower() in text.lower())
        
        return text, language, fake_words_count, real_words_count
    
    def get_bert_embedding(self, text):
        """Simulation d'embedding am√©lior√©e avec des vecteurs intelligents"""
        # Ce code g√©n√®re un embedding qui est influenc√© par le contenu du texte
        # pour donner des r√©sultats plus coh√©rents et r√©alistes
        
        # G√©n√©rer un vecteur de base
        np.random.seed(hash(text) % 10000)  # Assure la coh√©rence pour le m√™me texte
        embedding = np.random.rand(1, 768)  # Dimension typique d'un embedding BERT
        
        # Influencer le vecteur en fonction du contenu du texte
        processed_text, _, fake_count, real_count = self.preprocess_text(text)
        words = processed_text.split()
        
        # Ajuster le vecteur selon la proportion de mots associ√©s aux fake news
        if len(words) > 0:
            fake_ratio = fake_count / len(words)
            real_ratio = real_count / len(words)
            
            # Moduler certaines dimensions du vecteur en fonction de ces ratios
            # Les 100 premi√®res dimensions sont influenc√©es par les indicateurs de fake news
            embedding[0, :100] = embedding[0, :100] * (1 + fake_ratio)
            # Les 100 dimensions suivantes sont influenc√©es par les indicateurs de vraies news
            embedding[0, 100:200] = embedding[0, 100:200] * (1 + real_ratio)
        
        return embedding

# Configuration de la page
st.set_page_config(
    page_title="D√©tecteur de Fake News",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Fonction pour charger les mod√®les
# Fonction pour simuler le chargement des mod√®les (non utilis√©e dans cette version simplifi√©e)
def load_models_unused():
    """Fonction non utilis√©e dans cette version simplifi√©e"""
    pass

# Fonction pour pr√©dire si un texte est une fake news
def predict_fake_news(text, preprocessor, kmeans_model):
    """
    Pr√©dit si un texte est une fake news avec une analyse avanc√©e
    
    Args:
        text: Texte √† analyser
        preprocessor: Instance de TextPreprocessor
        kmeans_model: Mod√®le KMeans entra√Æn√©
    
    Returns:
        is_fake: Bool√©en indiquant si c'est une fake news
        probabilities: Probabilit√©s d'appartenance aux clusters
        processing_time: Temps de traitement en secondes
        language: Langue d√©tect√©e du texte
    """
    start_time = time.time()
    
    # Pr√©traitement du texte avec plus d'informations
    processed_text, language, fake_words_count, real_words_count = preprocessor.preprocess_text(text)
    
    # Obtention de l'embedding BERT influenc√© par le contenu
    embedding = preprocessor.get_bert_embedding(text)
    
    # Pr√©diction avec KMeans
    cluster = kmeans_model.predict(embedding)[0]
    
    # Calcul des distances aux centres des clusters de mani√®re explicite
    distances = np.array([np.linalg.norm(embedding[0] - center) for center in kmeans_model.cluster_centers_])
    probabilities = 1 / (1 + distances)
    probabilities = probabilities / np.sum(probabilities)
    
    # D√©terminer si le texte est une fake news
    is_fake_by_cluster = cluster == kmeans_model.fake_cluster
    
    # Ajuster la pr√©diction en fonction de l'analyse des mots-cl√©s
    # Si beaucoup plus de mots li√©s aux fake news que de mots li√©s aux vraies news
    if fake_words_count > real_words_count * 1.5:
        is_fake_by_keywords = True
        # Augmenter la probabilit√© du cluster fake news
        probabilities[kmeans_model.fake_cluster] = max(probabilities[kmeans_model.fake_cluster], 0.7)
    # Si beaucoup plus de mots li√©s aux vraies news que de mots li√©s aux fake news
    elif real_words_count > fake_words_count * 1.5:
        is_fake_by_keywords = False
        # Augmenter la probabilit√© du cluster vraies news
        probabilities[1 - kmeans_model.fake_cluster] = max(probabilities[1 - kmeans_model.fake_cluster], 0.7)
    else:
        is_fake_by_keywords = is_fake_by_cluster
    
    # D√©cision finale: si l'analyse des mots-cl√©s est forte, elle prime
    final_is_fake = is_fake_by_keywords if abs(fake_words_count - real_words_count) > 2 else is_fake_by_cluster
    
    # Normaliser les probabilit√©s
    probabilities = probabilities / np.sum(probabilities)
    
    processing_time = time.time() - start_time
    
    return final_is_fake, probabilities, processing_time, language

# Fonction pour afficher les r√©sultats
def display_results(is_fake, probabilities, processing_time, language):
    """
    Affiche les r√©sultats de la pr√©diction
    
    Args:
        cluster: Cluster pr√©dit
        probabilities: Probabilit√©s d'appartenance aux clusters
        n_clusters: Nombre de clusters
    """
    # D√©termination du type de news
    if is_fake:
        news_type = "Fake News"
        color = "red"
    else:
        news_type = "Vraie News"
        color = "green"
    
    # Affichage du r√©sultat
    st.markdown(f"<h2 style='text-align: center; color: {color};'>R√©sultat: {news_type}</h2>", unsafe_allow_html=True)
    
    # Affichage du temps de traitement et de la langue d√©tect√©e
    st.markdown(f"<p style='text-align: center;'>Temps de traitement: {processing_time:.3f} secondes | Langue d√©tect√©e: {language.upper()}</p>", unsafe_allow_html=True)
    
    # Affichage des probabilit√©s
    st.subheader("Probabilit√©s d'appartenance aux clusters")
    
    # Cr√©ation du DataFrame pour le graphique
    proba_df = pd.DataFrame({
        'Type': ['Fake News', 'Vraie News'],
        'Probabilit√©': [probabilities[0], probabilities[1]] if is_fake else [probabilities[1], probabilities[0]]
    })
    
    # Cr√©ation du graphique avec matplotlib
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(proba_df['Type'], proba_df['Probabilit√©'], color=['#FF6B6B', '#4CAF50'])
    
    # Personnalisation du graphique
    ax.set_xlabel("Cluster")
    ax.set_ylabel("Probabilit√© d'appartenance")
    ax.set_ylim(0, 1)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    
    # Ajout des valeurs sur les barres
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{height:.2f}', ha='center', va='bottom')
    
    # Affichage dans Streamlit
    st.pyplot(fig)
    
    # Explication de la pr√©diction
    st.subheader("Explication de la pr√©diction")
    
    if is_fake:
        st.markdown(
            """
            Ce texte a √©t√© class√© comme une **fake news** pour les raisons suivantes:
            - Pr√©sence de termes sensationnalistes ou d'affirmations exag√©r√©es
            - Absence de r√©f√©rences √† des sources fiables ou officielles
            - Structure et ton du langage typiques de contenu trompeur
            """
        )
    else:
        st.markdown(
            """
            Ce texte a √©t√© class√© comme une **vraie news** pour les raisons suivantes:
            - Ton neutre et informatif
            - Pr√©sence de termes associ√©s √† des sources fiables
            - Absence de sensationnalisme ou d'affirmations extr√™mes
            """
        )
    
    # Affichage d'un avertissement
    st.info(
        "Note: Cette pr√©diction est bas√©e sur une analyse lexicale et s√©mantique simplifi√©e. "
        "Pour une pr√©cision optimale, consultez plusieurs sources fiables."
    )

# Fonction principale
def main():
    """Fonction principale de l'application"""
    # Titre de l'application
    st.title("D√©tecteur de Fake News")
    
    # Initialisation du pr√©processeur simplifi√©
    preprocessor = SimpleTextPreprocessor()
    
    # Cr√©ation d'un mod√®le KMeans simplifi√© pour la d√©monstration
    n_clusters = 2
    kmeans_model = SimplifiedKMeans(n_clusters=n_clusters, random_state=42)
    
    # Centres des clusters (fake/real)
    kmeans_model.cluster_centers_ = np.array([
        np.random.rand(768),  # Fake news
        np.random.rand(768)   # Vraie news
    ])
    
    # Nombre de clusters (d√©fini √† 2 pour cette d√©monstration simplifi√©e)
    n_clusters = 2
    
    # Barre lat√©rale
    st.sidebar.title("Options")
    
    # S√©lection de la langue
    language = st.sidebar.radio(
        "Langue",
        ["Fran√ßais", "Anglais"],
        index=0
    )
    
    # Exemples de textes
    if language == "Fran√ßais":
        examples = [
            "Macron a d√©missionn√© de son poste de pr√©sident de la R√©publique.",
            "La France a remport√© la Coupe du Monde de football en 2018.",
            "Des scientifiques ont d√©couvert que les vaccins contre la COVID-19 contiennent des puces √©lectroniques pour nous surveiller."
        ]
    else:
        examples = [
            "Trump has won the 2020 presidential election by a landslide.",
            "NASA confirmed the existence of water on Mars.",
            "Scientists have discovered that COVID-19 vaccines contain microchips to track people."
        ]
    
    # S√©lection d'un exemple
    example = st.sidebar.selectbox(
        "Exemples de textes",
        [""] + examples,
        index=0
    )
    
    # Zone de texte pour la saisie
    if example:
        text = st.text_area("Saisissez un texte √† analyser", example, height=200)
    else:
        text = st.text_area("Saisissez un texte √† analyser", "", height=200)
    
    # Bouton pour lancer l'analyse
    if st.button("Analyser"):
        if text:
            # Affichage d'un spinner pendant l'analyse
            with st.spinner("Analyse en cours..."):
                # Pr√©diction am√©lior√©e
                is_fake, probabilities, processing_time, language = predict_fake_news(
                    text, preprocessor, kmeans_model
                )
                
                # Affichage des r√©sultats
                display_results(is_fake, probabilities, processing_time, language)
        else:
            st.error("Veuillez saisir un texte √† analyser.")
    
    # Informations sur l'application
    st.sidebar.markdown("---")
    st.sidebar.subheader("√Ä propos")
    st.sidebar.info(
        "Cette application est une d√©monstration simplifi√©e de d√©tection de fake news. "
        "Elle utilise un mod√®le simul√© pour illustrer le concept, sans d√©pendances externes. "
        "Pour une impl√©mentation compl√®te, consultez le code source original."
    )

if __name__ == "__main__":
    main()
